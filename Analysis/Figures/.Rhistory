timestamp_df = data.frame(psych_date = timestamp,
sid.x = subject)
vars <- colsplit(timestamp_df$psych_date, ",", c("date","time"))
timestamp_df$psych_date <- vars$date
# Convert timestamps to datestrings
bio_df <- merge(bio_df, timestamp_df)
bio_df$dob <- as.POSIXct(bio_df$dob, format="%Y-%m-%d")
bio_df$psych_date <- as.POSIXct(bio_df$psych_date, format="%Y-%m-%d")
bio_df$age_at_testing <- as.numeric(difftime(bio_df$psych_date,bio_df$dob,units="weeks")/52.25)
################ Bind together the reading results, bio, and psychometrics
master_df <- merge(bio_df, pm)
master_df <- merge(master_df, reading_df)
# Exclusion criterion
# Remove anyone tested before the experiment was finalized on 8-15
use_df <- subset(master_df, psych_date >= "2017-08-15")
# Remove any subjects less than 8 years old
use_df <- subset(use_df, age_at_testing >= 8 & age_at_testing <13)
# Remove any kids who have an auditory disorder
use_df <- subset(use_df, aud_dis == 0)
# Remove any subjects who have an IQ below 70.
use_df <- subset(use_df, wasi_fs2 >= 70)
# Remove any curves that are poorly fit
use_df <- subset(use_df, threshold >= 1 & threshold <= 7)
# Remove subjects who did not pass hearing screening or have a known neurological disorder
use_df <- subset(use_df, !(sid.x %in% c("IB701","KB630","IB706","IB263","HB656","HB213","IB319","HB742","GB727")))
# Get all the ABX trials and get the average slope/asymptote per individual
sub_df <- subset(use_df, sound2 != "Single")
sub_df <- mutate(sub_df, continuum = ifelse(sound2 %in% c("Sa","Sha"), "Sa-Sha", "Ba-Da"))
sub_df$id <- paste0(sub_df$sid.x, "_", sub_df$sound2)
# Generally, we want to remove ill-fitting psychometrics from the correlational study.
# In the main analysis, I do this by removing psychometrics whose threshold falls outside the range of the stimulus continuum [1-7]
# For the purpose of smooth estimation of correlations between WJ and slope- let's not remove different subjects for every prior width.
# Rather, let's just remove the ones that we do in the main analysis of the paper, i.e. when the prior width = 10
#excl_df <- sub_df %>% group_by(id, width) %>%
#  summarise(threshold = unique(threshold)) %>%
#  subset(width == 0.1) %>%
#  subset(threshold < 1 | threshold > 7 ) %>%
#  select(id)
#sub_df <- subset(sub_df, !(id %in% excl_df$id))
ABX_sum_big <- sub_df %>% group_by(sid.x,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
################### Bootstrap the correlation to compute standard errors ######################################
nsim <- 10000
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "Ba-Da"))
library(tidyr)
library(stringr)
library(reshape2)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
psychometrics <- read.csv("cleaned_psychometrics.csv")
group_levels <- c("Dyslexic", "Below Average", "Above Average", "Group Means")
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
psychometrics <- read.csv("cleaned_psychometrics.csv")
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
psychometrics <- read.csv("cleaned_psychometrics.csv")
getwd()
setwd('/home/eobrien/bde/Projects/Speech_contrasts')
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
psychometrics <- read.csv("cleaned_psychometrics.csv")
group_levels <- c("Dyslexic", "Below Average", "Above Average", "Group Means")
psychometrics$group <- factor(psychometrics$group, levels=group_levels)
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/CV_Leave_Out'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
cvpm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
if (grepl("Ba_Da", full_file_list[i])){
data$continuum = "Ba-Da"
}
else{
data$continuum = "Sa-Sha"
data$p <- 1 - data$p}
cvpm <- rbind(cvpm, data)}
subj_list <- unique(psychometrics$subject_id)
View(cvpm)
use_df <- cvpm %>% filter(SubjectID %in% subj_list)
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Fit_Uniform_Slope'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
pm <- rbind(pm, data)
}
colnames(pm)[1] <- "subject_id"
subj_list <- unique(psychometrics$subject_id)
use_df <- cvpm %>% filter(subject_id %in% subj_list)
colnames(pm)[1] <- "subject_id"
subj_list <- unique(psychometrics$subject_id)
use_df <- pm %>% filter(subject_id %in% subj_list)
View(use_df)
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/Results/Psychometrics/Fit_Uniform_Slope'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
pm <- rbind(pm, data)
}
colnames(pm)[1] <- "subject_id"
subj_list <- unique(psychometrics$subject_id)
use_df <- pm %>% filter(subject_id %in% subj_list)
sub_df <- subset(use_df, sound2 != "Single")
sub_df <- mutate(sub_df, continuum = ifelse(sound2 %in% c("Sa","Sha"), "/ʃa/~/sa/", "/ba/~/da/"))
sub_df$id <- paste0(sub_df$sid.x, "_", sub_df$sound2)#
View(sub_df)
sub_df$id <- paste0(sub_df$subject_id, "_", sub_df$sound2)#
View(sub_df)
ABX_sum_big <- sub_df %>% group_by(sid.x,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
ABX_sum_big <- sub_df %>% group_by(subject_id,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
View(sub_df)
View(use_df)
wj_df <- psychometrics %>% select(c("wj_brs","subject_id"))
wj_df <- psychometrics %>% select(c("wj_brs","subject_id")) %>% unique()
use_df <- pm %>% filter(subject_id %in% wj_df$subject_id)
use_df <- pm %>% filter(subject_id %in% wj_df$subject_id) %>% merge(.,wj_df)
View(use_df)
View(psychometrics)
df <- read.csv("cleaned_data.csv")
View(df)
setwd("/home/eobrien/projects/Speech_contrasts")
setwd("/home/eobrien/bde/Projects/Speech_contrasts")
df <- read.csv("RDRPRegistry_DATA_2018-01-02_1138.csv")
setwd("/home/eobrien/bde/Projects/Speech_contrasts_public")
rm(list=ls())
psychometrics <- read.csv("cleaned_psychometrics.csv")
group_levels <- c("Dyslexic", "Below Average", "Above Average", "Group Means")
psychometrics$group <- factor(psychometrics$group, levels=group_levels)
filepath = './Results/CV_Leave_Out'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
if (grepl("Ba_Da", full_file_list[i])){
data$continuum = "Ba-Da"
}
else{
data$continuum = "Sa-Sha"
data$p <- 1 - data$p}
pm <- rbind(pm, data)}
rm(list=ls())
filepath = '/home/eobrien/bde/Projects/Speech_contrasts/'
psychometrics <- read.csv("cleaned_psychometrics.csv")
psychometrics <- read.csv("cleaned_psychometrics.csv")
group_levels <- c("Dyslexic", "Below Average", "Above Average", "Group Means")
psychometrics$group <- factor(psychometrics$group, levels=group_levels)
filepath = './Results/Psychometrics/Fit_Uniform_Slope'
filelist = list.files(path = filepath,pattern = ".*.csv")
full_file_list <- paste0(filepath, '/',filelist)
pm <- data.frame()
for (i in 1:length(full_file_list)){
data<- read.csv(paste0(full_file_list[i]))
pm <- rbind(pm, data)
}
colnames(pm)[1] <- "subject_id"
wj_df <- psychometrics %>% select(c("wj_brs","subject_id")) %>% unique()
use_df <- pm %>% filter(subject_id %in% wj_df$subject_id) %>% merge(.,wj_df)
sub_df <- subset(use_df, sound2 != "Single")
sub_df <- mutate(sub_df, continuum = ifelse(sound2 %in% c("Sa","Sha"), "/ʃa/~/sa/", "/ba/~/da/"))
sub_df$id <- paste0(sub_df$subject_id, "_", sub_df$sound2)#
View(sub_df)
ABX_sum_big <- sub_df %>% group_by(subject_id,width,continuum) %>% summarise(mean_slope = mean(slope),
mean_end = mean((lapse+guess)/2),
wj_brs = unique(wj_brs),
mean_residuals = mean(residuals),
mean_deviance = mean(deviance))
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
##### Here be bootstraps ####
nsim <- 10000 # Number of bootstrap simulations to run
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
View(use_df)
View(sub_df)
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ba/~/da/"))
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ba/~/da/"))
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
##### Here be bootstraps ####
nsim <- 10000 # Number of bootstrap simulations to run
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ba/~/da/"))
View(ABX_sum_big)
View(ABX_sum_big)
View(ABX_sum_big)
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ba/~/da/"))
bootstrap_correlation <- function(ABX_sum){
r2slope <- vector("numeric", 10L)
r2end <- vector("numeric", 10L)
residuals <- vector("numeric", 10L)
deviance <- vector("numeric", 10L)
for (i in 1:length(unique(ABX_sum$width))){
this_width = unique(ABX_sum$width)[i]
lmfit <- lm(mean_slope ~ wj_brs, subset(ABX_sum, width == this_width))
r2slope[i] <- sqrt(summary(lmfit)$r.squared)
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, subset(ABX_sum, width == this_width))
r2end[i] <- sqrt(summary(lmfit)$r.squared)
# Get the summed deviance
sub <- subset(ABX_sum, width == this_width)
deviance[i] <- sum(sub$mean_deviance)
residuals[i] <- sum(sub$mean_residuals)
}
##### Here be bootstraps ####
nsim <- 10000 # Number of bootstrap simulations to run
rslope_sim <- vector("numeric", 1000L)
pslope_sim <- vector("numeric", 1000L)
rend_sim <- vector("numeric", 1000L)
pend_sim <- vector("numeric", 1000L)
mu_slope <- vector("numeric", 10L)
mu_p_slope <- vector("numeric", 10L)
mu_p_end <- vector("numeric", 10L)
mu_end <- vector("numeric", 10L)
se_slope <- vector("numeric", 10L)
se_end <- vector("numeric", 10L)
for (h in 1:length(unique(ABX_sum$width))){
sub <- subset(ABX_sum, width == unique(ABX_sum$width)[h])
for (i in 1:nsim){
sampler <- sub[sample(nrow(sub), replace = TRUE), ]
lmfit <- lm(mean_slope ~ wj_brs, sampler)
rslope_sim[i] <- sqrt(summary(lmfit)$r.squared)
pslope_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
# Same thing for the endpoints
lmfit <- lm(mean_end ~ wj_brs, sampler)
rend_sim[i] <- sqrt(summary(lmfit)$r.squared)
pend_sim[i] <- anova(lmfit)$'Pr(>F)'[1]
}
mu_slope[h] <- mean(rslope_sim)
mu_end[h] <- mean(rend_sim)
mu_p_slope[h] <- mean(pslope_sim)
mu_p_end[h] <- mean(pend_sim)
se_slope[h] <- sd(rslope_sim)
se_end[h] <- sd(rend_sim)
}
mu_end[1] <- 0
se_end[1] <- 0
mu_p_end[1] <-1
dfslope <- data.frame(Correlation = mu_slope, SE = se_slope, p = mu_p_slope, Type = "Slope", Width =  unique(ABX_sum$width))
dfasym <- data.frame(Correlation = mu_end, SE = se_end, p = mu_p_end,Type = "Asymptote", Width = unique(ABX_sum$width))
df <- rbind(dfslope, dfasym)
df$is_significant = df$p < 0.05
return(df)}
df1 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ba/~/da/"))
df2 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ʃa/~/sa/))
df2 <- bootstrap_correlation(subset(ABX_sum_big, continuum == "/ʃa/~/sa/"))
px1 <- ggplot(df1, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=4, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle("/ba/-/da/")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px1
px1 <- ggplot(df1, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=4, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle("/ba/~/da/")+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px1
px2 <- ggplot(df2, aes(Width, Correlation, group = Type, colour = Type)) +
geom_point(size=4, aes(shape = is_significant))+
scale_shape_manual(values = c(1,16))+
geom_smooth(se = FALSE)+
geom_ribbon(aes(ymin=Correlation - SE, ymax= Correlation + SE, fill = Type),alpha = 0.2,size = 0.1)+
scale_fill_manual("Parameter",values=c("gray10","darkseagreen"))+
theme_bw()+
scale_color_manual("Parameter",values=c("gray7","darkseagreen"))+
xlab("Asymptotic Prior Width")+
ylab("Correlation with WJ-BRS")+
ggtitle('/ʃa/~/sa/')+
theme(legend.position = c(0.8,0.1),
legend.background = element_rect(fill = alpha("white",0.4), colour = NA),
text = element_text(size=24),
plot.margin = unit(c(1,1,1,2),"lines"))+
guides(fill=guide_legend(title="Parameter"),
shape = FALSE)
px2
myplot1 <- arrangeGrob(px2, top = textGrob("A", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot2 <- arrangeGrob(px1, top = textGrob("B", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
px <- grid.arrange(myplot1, myplot2, nrow = 1)
myplot1 <- arrangeGrob(px1, top = textGrob("A", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
myplot2 <- arrangeGrob(px2, top = textGrob("B", x = unit(0, "npc")
, y = unit(0.5, "npc"), just=c("left","top"),
gp=gpar(col="black", fontsize=54)))
px <- grid.arrange(myplot1, myplot2, nrow = 1)
ggsave("figure_correlation_wrt_prior", px, device = cairo_ps, width = 15, height = 10)
setwd("./Analysis/Figures")
ggsave("figure_correlation_wrt_prior", px, device = cairo_ps, width = 15, height = 10)
ggsave("figure_correlation_wrt_prior.pdf", px, width = 15, height = 10
("./Images/","Figure_7.tiff"), px,  width = 15, height = 10, dpi = 300)
ggsave("figure_correlation_wrt_prior.png", px, width = 15, height = 10
("./Images/","Figure_7.tiff"), px,  width = 15, height = 10, dpi = 300)
ggsave("figure_correlation_wrt_prior.png", px, width = 15, height = 10)
ggsave("figure_correlation_wrt_prior.pdf", px, width = 15, height = 10)
warnings()
